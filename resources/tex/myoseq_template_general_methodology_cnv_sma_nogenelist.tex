{\Large \textbf{\underline{General Methodology}}}
\\ \\ \\
{\large \textbf{\textit{Exome Sequencing}}}
\\
We performed whole exome sequencing on DNA samples at the Broad Institute's Genomics Platform, using Illumina exome capture, 37 Mb baited target, and the Broad's in-solution hybrid selection process. For input DNA we used \textgreater250 $ng$ of DNA, at \textgreater4 $ng/\mu l$. Our exome-sequencing pipeline included sample plating, library preparation (2-plexing of samples per hybridization), hybrid capture, sequencing (*150* bp paired reads), sample identification QC check, and data storage. Our hybrid selection libraries cover \textgreater85\% of targets at 20x, comparable to ~55x mean coverage. The exome sequencing data was de-multiplexed and each sample's sequence data were aggregated into a single Picard BAM file.
\\ \\ \\
{\large \textbf{\textit{Variant Calling, Filtering and Annotation}}}
\\
Exome sequencing data was processed through a pipeline based on \textit{Picard}, using base quality score recalibration and local 
realignment at known indels. We used the \textit{BWA} aligner for mapping reads to the human genome build 37 (hg19). Single Nucleotide Polymorphism (SNPs) 
and insertions/deletions (indels) were jointly called across all samples using \textit{Genome Analysis Toolkit (GATK)} HaplotypeCaller package version 3.1. 
Default filters were applied to SNP and indel calls using the GATK Variant Quality Score Recalibration (VQSR) approach. 
Lastly, the variants were annotated using \textit{Variant Effect Predictor (VEP)}.
\\ \\ \\
{\large \textbf{\textit{Ancestry Inference}}}
\\
Ancestry inference was performed by projecting genotypes from individuals onto principal components from The Genome Aggregation Consortium (gnomAD) ancestry analysis, comprising 94,176 common, bi-allelic, autosomal SNVs pruned to avoid linkage disequilibrium. A random forests classifier trained on the gnomAD dataset was used to assign an ancestry to individuals for whom the label probability was greater than 90\%. This analysis is able to identify individuals with Finnish (fin), non-Finnish European (nfe), South Asian (sas), East Asian (eas), African (afr), Latino (amr), or Ashkenazi Jewish (asj) ancestry. Individuals not confidently assigned an ancestry label were assigned to the other (oth) ancestry category. 
\\ \\ \\
{\large \textbf{\textit{Sex Inference}}}
\\
The chromosomal sex of the individual was computed using the Hail Python library. Normalized Y coverage was calculated using average filtered depth for non-pseudoautosomal regions of the Y chromosome, normalized to the average coverage on chromosome 20. An F statistic for X chromosome heterozygosity was generated using Hail's \textit{impute\_sex()} method. Based on F statistic and normalized Y coverage thresholds, the individual was assigned one of four sex descriptions: ambiguous sex, female, male, or sex aneuploidy. Individuals designated as ambiguous sex have intermediate levels of X heterozygosity that fall in between the confident male and female ranges. Samples with sex aneuploidy have either a confidently male F statistic value with no normalized Y coverage, or a confidently female F statistic with significant normalized Y coverage. 
\\ \\ \\
{\large \textbf{\textit{Gene coverage}}}
\\
The coding bases (including 10 bp flanking region) of the candidate genes was determined using the Gencode v19 regions. The per base coverage of each
sample was determined using \textit{samtools depth}. Only reads with mapping quality (MQ) $\geq$20 and bases with base quality (BQ) $\geq$10
were included in the coverage metric. Lastly, bases with from overlapping reads were only counted once. A site with coverage \textgreater6 was considered
callable.  
\\ \\ \\
{\large \textbf{\textit{Analysis}}}
\\
The variant call set was uploaded on to \textit{seqr} and an analysis limited to the candidate gene list was performed using the various 
inheritance patterns. The main report contains variants restricted to nonsense, frameshift, essential splice site and missense variants and filtered on variant site and genotype quality. The appendix listing each gene contains all variants discovered regardless of annotation and quality.
\\ \\ \\
{\large \textbf{\textit{Genome Aggregation Database (gnomAD) data set}}}
\\
The Genome Aggregation Database (gnomAD) is a resource developed by an international coalition of investigators, with the goal of aggregating and harmonizing both exome and genome sequencing data from a wide variety of large-scale sequencing projects, and making summary data available for the wider scientific community. The data set contains nearly 200,000 unrelated individuals sequenced as part of various disease-specific and population genetic studies. The allele frequencies are summarized into the major ancestries European, Non-Finnish European, Ashkenazi Jewish,  South Asian, East Asian, African, and Latino. For more details, please visit: http://gnomad.broadinstitute.org/about
\\ \\ \\

\newpage
{\large \textbf{\textit{ClinVar Database}}}
\\
ClinVar is a freely accessible, public archive of reports of the relationships among human variations and phenotypes, with supporting evidence. The level of confidence in the accuracy of variation calls and assertions of clinical significance depends in large part on the supporting evidence and is variable for the variants included in ClinVar. A review status (stars) is also assigned by ClinVar to each variant, to indicate the level of supporting evidence. 
\\ \\

\begin{small}
\begin{tabular}{ |p{1cm}|p{15cm}|  }
\hline
\textbf{Stars} & \textbf{Review Status} \\
\hline
None & Either conficting interpretations (in which case the independent values are enumerated), or no submitter provided an interpretation \\
1 & One submitter provided an interpretation (classified by single submitter) \\
2 & Two or more submitters provided the same interpretation (classified by multiple submitters) \\
3 & Reviewed by expert panel \\
4 & Practice guideline (reviewed by professional society) \\
\hline
\end{tabular}
\end{small}
\\ \\ \\

{\large \textbf{\textit{Copy Number Variant (CNV) detection from Exome Sequencing Data}}}
\\
The Germline CNV caller (gCNV) is a read based detection method that was used to call CNVs from exome sequencing data. Briefly, read counts for each exon was determined for a sample along with at least 50 other exomes that are technically similar. CNV detection uses a probabilistic model to infer copy number across the exome.
\\ \\ 

{\large \textbf{\textit{SMA carrier detection from exome sequencing data}}}
\\
The probability of being a Spinal Muscular Atrophy (SMA) carrier was calculated according to the methods
described in Larson et al (2015) using the scripts available at https://github.com/klaricch/sma{\textunderscore}carrier{\textunderscore}detection \\ 
\\ \\ 

{\large \textbf{\textit{Tools/Resources}}}
\\ \\
\begin{small}
\begin{tabular}{ |p{6cm}|p{10cm}|  }
\hline
\textbf{Tool/Resource} & \textbf{Link} \\
\hline
BWA & https://github.com/lh3/bwa \\
ClinVar & http://www.ncbi.nlm.nih.gov/clinvar \\
Genome Analysis Toolkit (GATK) & https://www.broadinstitute.org/gatk \\
gCNV & https://software.broadinstitute.org/gatk/documentation/tooldocs/current/ \\
{} & org\_broadinstitute\_hellbender\_tools\_copynumber\_GermlineCNVCaller.php  \\
Gencode v19 & http://www.gencodegenes.org/releases/19.html \\
Genome Aggregation Database (gnomAD) & http://gnomad.broadinstitute.org/ \\
Hail & https://hail.is/index.html \\
Picard & https://github.com/broadinstitute/picard \\
samtools & https://github.com/samtools/samtools \\
seqr & https://seqr.broadinstitute.org \\
SMA carrier detection & https://github.com/klaricch/sma\_carrier\_detection \\
Variant Effect Predictor (VEP) & http://www.ensembl.org/info/docs/tools/vep/index.html \\ 
\hline
\end{tabular}
\end{small}
\newpage
